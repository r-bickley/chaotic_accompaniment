{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaotic Accompaniment\n",
    "#In general: Listens to room audio, performs frequency analysis, consturcts an array\n",
    "#of prominent constituent frequencies, and performs an arpeggio using these as notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy import stats\n",
    "import scipy.signal as signal\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from __future__ import print_function\n",
    "import scipy.io.wavfile as wavfile\n",
    "import scipy\n",
    "import scipy.fftpack\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "from pysine import sine\n",
    "import random\n",
    "from threading import Thread\n",
    "import time\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording step: records 0.25s of audio for analysis\n",
    "def record_snippet(window):\n",
    "    CHUNK = 1000\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = window\n",
    "    WAVE_OUTPUT_FILENAME = 'sample.wav'\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    return WAVE_OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFT analysis step\n",
    "def do_fft(filename):\n",
    "    fs_rate, signal = wavfile.read(filename)\n",
    "    l_audio = len(signal.shape)\n",
    "    if l_audio == 2:\n",
    "        signal = signal.sum(axis=1) / 2\n",
    "    N = signal.shape[0]\n",
    "    secs = N / float(fs_rate)\n",
    "    Ts = 1.0/fs_rate # sampling interval in time\n",
    "    t = scipy.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
    "    FFT = abs(scipy.fft(signal))\n",
    "    FFT_side = FFT[range(N//2)] # one side FFT range\n",
    "    freqs = scipy.fftpack.fftfreq(signal.size, t[1]-t[0])\n",
    "    fft_freqs = np.array(freqs)\n",
    "    freqs_side = freqs[range(N//2)] # one side frequency range\n",
    "    fft_freqs_side = np.array(freqs_side)\n",
    "\n",
    "    freqs = freqs_side[30:]\n",
    "    values = abs(FFT_side)[30:]\n",
    "    return (freqs, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find maximum between 30 and 55Hz\n",
    "#Find maximum between 55 and 110Hz\n",
    "#Max between 110 and 220Hz\n",
    "#Max between 220 and 440\n",
    "#Between 440 and 600\n",
    "#Between 600 and 880\n",
    "#Between 880 and 1760\n",
    "#A piano keyboard goes up to 4186, but pure tones in that range sound like a medical hearing test\n",
    "\n",
    "def get_w(freqs, values):\n",
    "    w_ns = []\n",
    "    #find the first frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 0\n",
    "    f_max = 55\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the second frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 55\n",
    "    f_max = 110\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the third frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 110\n",
    "    f_max = 220\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the fourth frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 220\n",
    "    f_max = 440\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the fifth frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 440\n",
    "    f_max = 600\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the sixth frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 600\n",
    "    f_max = 880\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #find the seventh frequency\n",
    "    max_amp = 0\n",
    "    max_freq = 0\n",
    "    f_min = 880\n",
    "    f_max = 1760\n",
    "    for i in range(len(freqs)):\n",
    "        if f_min<freqs[i]<f_max:\n",
    "            if values[i] > max_amp:\n",
    "                max_amp = values[i]\n",
    "                max_freq = freqs[i]\n",
    "    w_ns.append(max_freq)\n",
    "    #return the array\n",
    "    return w_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arpeggiate(notes,blips,bliplength):\n",
    "    for i in range(blips):\n",
    "        sine(frequency=notes[random.randint(0,6)], duration=bliplength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(cycles,blips,bliplength,window):\n",
    "    j=0\n",
    "    while(j<cycles):        \n",
    "        record_snippet(window)\n",
    "        arpeggiate(get_w(do_fft('sample.wav')[0],do_fft('sample.wav')[1]),blips,bliplength)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous performance: only recommended for use with headphones, or when audio input and output are well-separated\n",
    "#To use: adjust the number of cycles, clip duration, and bliplength in the script, then run.\n",
    "myqueue = Queue(10)\n",
    "class ProducerThread(Thread):\n",
    "    def run(self):\n",
    "        global myqueue\n",
    "        cycles = 20\n",
    "        j = 0\n",
    "        while(j<cycles):\n",
    "            record_snippet(1.0)\n",
    "            myqueue.put(get_w(do_fft('sample.wav')[0],do_fft('sample.wav')[1]))\n",
    "            time.sleep(0.3)\n",
    "            j += 1\n",
    "\n",
    "class ConsumerThread(Thread):\n",
    "    def run(self):\n",
    "        global queue\n",
    "        cycles = 20\n",
    "        j = 0\n",
    "        while(j<cycles):\n",
    "            notes = myqueue.get()\n",
    "            arpeggiate(notes,20,0.3)\n",
    "            myqueue.task_done()\n",
    "            time.sleep(0.3)\n",
    "            j += 1\n",
    "            \n",
    "ProducerThread().start()\n",
    "ConsumerThread().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use: perform(cycles,blips,bliplength,window)\n",
    "#cycles is the number of listen / play rounds the instrument will perform\n",
    "#blips is the number of notes the instrument will play per cycle\n",
    "#bliplength is the duration of each note that the instrument will play\n",
    "#window is the amount of time that the instrument will listen between rounds\n",
    "perform(20,20,0.3,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
